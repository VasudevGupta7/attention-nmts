# Neural Machine Translation System with Attention
Implemented the seq2seq model with Luong attention for building NMTS

## Tried to implement model based on following research papers:
- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
- [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)

## Model Architecture
<img src="assets/model.png" width="700" height="400"/>

## Encoder
<img src="assets/encoder_summary.png" width="700" height="400"/>

## Decoder
<img src="assets/decoder_summary.png" width="700" height="400"/>

## Running this Project
To run this project execute the following command:<br>
`python3 main.py`<br>
To translate english to german execute the following command:<br>
`python3 translate2german.py`
